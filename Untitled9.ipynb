{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a8533-635d-4bc1-9d5a-67b7157669df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TensorFlow and Keras for model building\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# 2. Numpy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# 3. Matplotlib for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 4. OS for file operations\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7909be0-ce7a-4e18-8c39-ce6ab0ab408b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Tomato_Bacterial_spot, Number of images: 300\n",
      "Class: Tomato_Early_blight, Number of images: 300\n",
      "Class: Tomato_healthy, Number of images: 300\n",
      "Class: Tomato_Late_blight, Number of images: 300\n",
      "Class: Tomato_Leaf_Mold, Number of images: 300\n",
      "Class: Tomato_Septoria_leaf_spot, Number of images: 300\n",
      "Class: Tomato_Spider_mites_Two_spotted_spider_mite, Number of images: 300\n",
      "Class: Tomato__Target_Spot, Number of images: 300\n",
      "Class: Tomato__Tomato_mosaic_virus, Number of images: 300\n",
      "Class: Tomato__Tomato_YellowLeaf__Curl_Virus, Number of images: 300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_path = r\"C:\\Users\\ELCOT\\Downloads\\plantvillage\"  # replace with your dataset path\n",
    "\n",
    "# List the subfolders (which are the classes) inside the dataset\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Check how many classes and how many images in each class\n",
    "for class_name in classes:\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):  # Make sure it's a folder\n",
    "        num_images = len(os.listdir(class_folder))  # Count images in the class folder\n",
    "        print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a75266-95ca-4b24-8717-ceb3e9f6b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation generators with split\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Split 20% for validation\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Must match train split\n",
    ")\n",
    "\n",
    "# Flow training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # 80%\n",
    ")\n",
    "\n",
    "# Flow validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # 20%\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='test'  # 10%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0ad2d8-7db1-495f-89b9-e3237fa8d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')  # 10 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feef5c0-014b-49da-8b5d-86c2a37ddeaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ELCOT\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m901s\u001b[0m 11s/step - accuracy: 0.2184 - loss: 4.7759 - val_accuracy: 0.1042 - val_loss: 32.2682\n",
      "Epoch 2/20\n",
      "\u001b[1m16/75\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:58\u001b[0m 11s/step - accuracy: 0.3693 - loss: 1.8237"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Adam optimizer with learning rate\n",
    "    loss='categorical_crossentropy',  # For multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,  # Training data\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Number of steps per epoch\n",
    "    epochs=20,  # You can adjust this number based on your requirements\n",
    "    validation_data=val_generator,  # Validation data\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size  # Number of validation steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761edb8-d9eb-407b-90f2-9584b03e0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load and preprocess the image\n",
    "img_path = r'C:\\Users\\ELCOT\\Downloads\\bacterial spot.jpg'  # Replace with your test image path\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.  # Normalize\n",
    "\n",
    "# Step 2: Make prediction\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(prediction[0])\n",
    "\n",
    "# Step 3: Get class labels\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "predicted_class_name = class_labels[predicted_class_index]\n",
    "\n",
    "# Step 4: Show result\n",
    "print(\"Predicted Class Index:\", predicted_class_index)\n",
    "print(\"Predicted Class Name:\", predicted_class_name)\n",
    "\n",
    "# Optional: Show the image\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Prediction: {predicted_class_name}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b64268-41f2-481f-a4df-24b88ab0c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e866ca-fd33-490a-aa0e-0692c07ac5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tomato_disease_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2facdec-ec5c-4e5d-879d-e5bbe2724b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"tomato_disease_model.h5\")\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Specify the path to save the model in your Documents folder\n",
    "save_path = r\"C:\\Users\\ELCOT\\Documents\\tomato_disease_model.tflite\"  # Update this path if necessary\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open(save_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbe06e7-2f1d-498e-be39-74018f6f3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['accuracy'])         # training accuracy per epoch\n",
    "print(history.history['val_accuracy'])     # validation accuracy per epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f6bf1-490d-42a1-bcf6-ec221463be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826fabf-b3e6-4515-951f-9516010941f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
